function [F,P] = olrp(beta,A,B,R,Q,H)%function [f,p] = olrp(beta,A,B,R,Q,H)%%OLRP can have arguments: (beta,A,B,Q,R) if there are no cross products%     (i.e. W=0).  Set beta=1, if there is no discounting.%     OLRP calculates f of the feedback law:%		u = -fx%  that maximizes the function:%          sum {beta^t [x'Rx + u'Qu +2x'Hu] }%  subject to %		x[t+1] = Ax[t] + Bu[t] %  where x is the nx1 vector of states, u is the kx1 vector of controls,%  A is nxn, B is nxk, R is nxn, Q is kxk, H is nxk.%    Also returned is P, the steady-state solution to the associated %  discrete matrix Riccati equation.m = max(size(A));[~,cb] = size(B);if nargin == 5     H = zeros(m,cb);endif min(abs(eig(Q))) > 1e-8    A = sqrt(beta)*(A-B*(Q\H'));    B = sqrt(beta)*B;    R = R-H*(Q\H');    [k,s] = doubleo(A',B',R,Q);    F = k'+(Q\H');    P = s;else    p0 = -.01*eye(m);    dif = 1;    iter = 0;  while (dif > 1e-8 && iter < 1000)    f0 = (Q+beta*B'*p0*B)\(beta*B'*p0*A+H');    p1 = beta*A'*p0*A + R -(beta*A'*p0*B+H)*f0;    f1 = (Q+beta*B'*p1*B)\(beta*B'*p1*A+H');    dif = max(max(abs(f1-f0)));    iter = iter+1;    p0 = p1;  end  if iter >= 1000      disp('WARNING: Iteration limit of 1000 reached in olrp.m');   end  F = f1;  P = p0;end